{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-success\">\n",
    "\n",
    "# <span style='color:Blue'>This notebook provides a tutorial for the <span style='color:purple'>nightingale_parallel</span> inference module. We'll use a fully trained OMITTED model provided in Nightingale/Inference/model to overview how to load a model and run inference with the module. \n",
    "    \n",
    "## Make sure you are running the *nightingale_env* kernel in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nightingale_parallel import Detector\n",
    "import time # not required, only used for this notebook\n",
    "import logging # nightingale_parallel uses python's logging api to log progress\n",
    "logging.basicConfig(filename='detector_test.log',level=logging.INFO) # check for this file in your directory for logging progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-success\">\n",
    "\n",
    "# The <span style='color:purple'>nightingale_parallel</span> module is composed of the \"Detector\" class and it's \"predict\" function. You'll use the Detector class to initialize a detector instance, and then run the instance with the \"predict\" function to perfrom inference on an image. Below is the docstring followed by executable examples. \n",
    "\n",
    "## The API usage for instantiating a detector:\n",
    "\n",
    "```\n",
    "class Detector():\n",
    "    \n",
    "    def __init__(self,gpu_ids,placeholder=(2048,2048,3),allow_growth=False,model='model/omitted_scrdet_Frozen.pb'):\n",
    "'''\n",
    "        Assign GPU IDs and Initialize Model Weights\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        gpu_ids : int, [int] or csv string assigning specific GPUs for this process.\n",
    "                    Current version supports multiple GPUs for parallel processing\n",
    "                    of large images. \n",
    "                    \n",
    "        placeholder : 3D tuple (rows,cols,channels) sets sliding window size used to\n",
    "                        process arbitrarily sized imagery and reserves memory on the\n",
    "                        GPU's. Imagery smaller than placeholder will be zero-padded. \n",
    "                        Default is (2048,2048,3). Has been successfully tested up to\n",
    "                        shape of (4096,4096,3) on a Tesla V100-DGXS-32GB GPU. \n",
    "                        \n",
    "        allow_growth : bool. Whether or not to allow other processes to allocate GPU memory\n",
    "                        on the GPU's you are using. Default is False. If you are maxing\n",
    "                        out GPU memeory with very large images (e.g., 4096,4096,3), you\n",
    "                        will want this set to False. For futher info, see Tensorflow's\n",
    "                        documentation for tf.ConfigProto gpu_options.allow_growth\n",
    "                        \n",
    "        model : string, path to the tensorflow frozen graph .pb file\n",
    "        '''\n",
    "```\n",
    "## The API usage for inferencing the detector instance:\n",
    "```\n",
    "    def predict(self,file,clips = None, conf = 0.01,\n",
    "                class_list = False,\n",
    "                virtual_mem=False, nms_iou = 0.2, h_overlap = 200,\n",
    "                w_overlap = 200, max_nms_output = 200):\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        file : str\n",
    "            Complete path to an image, or path to a directory of images\n",
    "        \n",
    "        clips : list[[y0_0,x0_0,y1_0,x1_0],...[y0_n,x0_n,y1_n,x1_n]]\n",
    "            A list of lists containing pixel values used to clip out a portion or portions of the image for \n",
    "            processing. Can be left as  clips = None to process the whole image (this is \n",
    "            default). Must be formatted as a list of list, so passing a single clip would be formatted as \n",
    "            clips = [[row0,col0,row1,col1]]. Clips are not supported if passing in a directory of \n",
    "            images for processing. Pass a single image with clips locations if you want to use clips. If clips are\n",
    "            passed in, then virtual_mem will automatically be disabled (set to False).\n",
    "        \n",
    "        conf : float (0,1] or list of floats where each value corresponds to a specific class confidence\n",
    "            Output detection if detection confidence score is greater than or equal to this value\n",
    "            \n",
    "        class_list : list of strings\n",
    "            A name for each class\n",
    "        \n",
    "        virtual_mem : Bool\n",
    "            Reduce memory consumption by treating NITF imagery as a virtual array, where smaller portions of the \n",
    "            NITF image are read into memory as they are needed for processing. Reduces time up front by \n",
    "            preventing the whole NITF being read into memory, but results in longer processing time overall. \n",
    "            If clips are passed in, then virtual_mem setting is overwritten and set to False.\n",
    "            \n",
    "        nms_iou : float; Non-Max Supression IoU threshold.\n",
    "\n",
    "        *_overlap : int; h (height/vertical) or w (width/horizontal) pixel overlap for tiled/sliding image \n",
    "            processing window(s). Size of processing window is set by the \"placeholder\" parameter\n",
    "            when the detector is initialized.\n",
    "\n",
    "        max_nms_output : int; maximum number of detections to return from nms function. \n",
    "\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            A pandas dataframe containing the following colums:\n",
    "                * id - int, detection id (index of dataframe)\n",
    "                * geometry - Shapely formatted polygon in NITF pixel coordinates\n",
    "                * class - string, object class\n",
    "                * conf - float in (0,1]\n",
    "                * image_name - string\n",
    "                * (class) - list of floats, confidence score for each class, including background\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Initialize the detector with default settings using GPU #2 and GPU #0 (assumes you have at least 3 GPU's accessible )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time =  79.05209755897522\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "detector = Detector([2,0])\n",
    "end = time.time()\n",
    "print('Elapsed time = ',end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify an image to run. We'll specify the test image from our \"OMITTED_TEST_Data_Nightingale_Format.csv\" file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'Sample_NITF/omitted.r0.ntf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2a) Run detector on a NITF with some pre-determined NITF clips.\n",
    "# Note that the clip format is clip=[[y0_0,x0_0,y1_0,x1_0],...[y0_n,x0_n,y1_n,x1_n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time =  13.214110851287842\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "clips = [[8000, 11000, 11000, 14000],[10000, 200, 12500, 3000],[15000,15000,17000,17000]]\n",
    "predictions_clip = detector.predict(file=file,clips=clips,class_list=['class1','class2','class3'])\n",
    "end = time.time()\n",
    "print('Elapsed time = ',end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2b) Alternatively, run detector on the whole NITF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# predictions_full = detector.predict(file=file,class_list=['class1','class2','class3'])\n",
    "# end = time.time()\n",
    "# print('Elapsed time = ',end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2c) Or, you can pass in a directory of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# predictions_folder = detector.predict(file='Sample_NITF',class_list=['class1','class2','class3'])\n",
    "# end = time.time()\n",
    "# print('Elapsed time = ',end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Verify the output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(predictions_clip))\n",
    "predictions_clip.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Save the detections dataframe to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_clip.to_csv('Test&Evaluate/my_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-success\">\n",
    "    \n",
    "# From here, you can now open the <span style='color:purple'>Test&Evaluate</span> folder to evaluate your results text file. The next cells are just an example for plotting the results on your NITF. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Plot the whole NITF with prediction results from the clip run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell imports tools for reading and plotting\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib import cm, colors\n",
    "from osgeo.gdal import Open as gdalOpen\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done            \n"
     ]
    }
   ],
   "source": [
    "## This cell reads and adjusts an image\n",
    "\n",
    "##################\n",
    "#### READ PNG ####\n",
    "##################\n",
    "#img = cv2.imread(file)\n",
    "######################\n",
    "######################\n",
    "\n",
    "##################\n",
    "### READ NITF ####\n",
    "##################\n",
    "my_nitf = gdalOpen(file)\n",
    "text = 'Reading Image...'\n",
    "print(text,end=\"\\r\")\n",
    "img = my_nitf.GetRasterBand(1).ReadAsArray()\n",
    "#################################################\n",
    "#### optionally adjust nitf visibility ##########\n",
    "from nightingale_parallel import adjust_image ########\n",
    "bits = int(my_nitf.GetMetadata()['NITF_ABPP'])###\n",
    "img = adjust_image(img,bit_depth_in=bits) #######\n",
    "#################################################\n",
    "#################################################\n",
    "print(' '*len(text),end=\"\\r\")\n",
    "print('Done')\n",
    "##########################\n",
    "##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell plots everything\n",
    "fig1,ax = plt.subplots(figsize=(100,100))\n",
    "ax.imshow(img,cmap='gray');\n",
    "classes = np.array(sorted(predictions_clip['class'].unique()))\n",
    "colors = cm.get_cmap('rainbow',len(classes))\n",
    "\n",
    "# plot the detections\n",
    "for index, row in predictions_clip[predictions_clip['conf'] > 0.8].iterrows():\n",
    "    cli = np.where(classes == row['class'])[0][0]\n",
    "    ax.plot(*row['geometry'].exterior.xy,c=colors(cli))\n",
    "    \n",
    "# plot the clips    \n",
    "for clip in clips:\n",
    "    xs = [clip[1],clip[1],clip[3],clip[3],clip[1]]\n",
    "    ys = [clip[0],clip[2],clip[2],clip[0],clip[0]]\n",
    "    ax.plot(xs,ys,'g',linewidth=4)\n",
    "\n",
    "legend_elements = []\n",
    "for c in classes:\n",
    "    cli = np.where(classes == c)[0][0]\n",
    "    legend_elements.append(Patch(color=colors(cli),label=c))\n",
    "ax.legend(handles=legend_elements,loc='upper left',fontsize=60);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image output omitted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nightingale_env",
   "language": "python",
   "name": "nightingale_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
