{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-success\">\n",
    "\n",
    "# <span style='color:Blue'> NOTEBOOK 4: Export the model for inference and testing\n",
    "    \n",
    "## Make sure you are running the *nightingale_env* kernel in this notebook\n",
    "\n",
    "## After model training has completed, use Nightingale's \"nightingale_model_exportpb\" module to export a Tensorflow checkpoint to a frozen graph for model testing, evaluation, and deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++--++--++--++--++--++--++--++--++--++--++--++--++--++--++--++--++--++--++--++--\n",
      "The ROOT_PATH is  /home/on22851/Old_Before_Working_Directory/Nightingale/Training/\n"
     ]
    }
   ],
   "source": [
    "from libs.export_pbs import nightingale_model_exportpb # import the model export module\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-success\">\n",
    "\n",
    "## 1) Choose the Tensorflow checkpoint that you want to export from the output/trained_weights folder. Note that there are multiple files associated with a single checkpoint (e.g., *.ckpt.meta, *.ckpt.index, *.ckpt.data). You'll specify the checkpoint by only specifying the filename+.ckpt (ignoring the \".meta\", \".index\", and \".data\"). For example, if you have checkpoint files with the names \n",
    "\n",
    "     OMITTED_24000model.ckpt.data-00000-of-00001\n",
    "     OMITTED_24000model.ckpt.index\n",
    "     OMITTED_24000model.ckpt.meta\n",
    "     \n",
    "## you'd specify the checkpoint file as\n",
    "\n",
    "    OMITTED_24000model.ckpt\n",
    "\n",
    "## 2) You'll also set an output directory and output name for the model. Note that the the exported model file will end with \"_Frozen.pb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_PATH = 'output/trained_weights/MyCoolExperiment/OMITTED_24000model.ckpt' # the full path the the .ckpt\n",
    "OUT_DIR = 'my_models/nightingale_omitted_tutorial/' # where to save the model (will get made id non existent)\n",
    "PB_NAME = 'ntngl_omitted' # the name you are giving the model file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-success\">\n",
    "\n",
    "## 3) Run the export function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "nightingale_model_exportpb.export_frozenPB(CKPT_PATH,OUT_DIR,PB_NAME) # export function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-success\">\n",
    "\n",
    "# <span style='color:Blue'> Congratulations on completing all the steps for training and exporting the model!!! You can move on to the Nightingale/Inference folder to test and evaluate a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nightingale_env",
   "language": "python",
   "name": "nightingale_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
