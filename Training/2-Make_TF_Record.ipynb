{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-success\">\n",
    "\n",
    "# <span style='color:Blue'> NOTEBOOK 2: Convert Training Data to a Tensorflow Record </span>\n",
    "\n",
    "## Make sure you are running the *nightingale_env* kernel in this notebook\n",
    "\n",
    "##  Using a Nightingale-formatted groundtruth CSV (created in Notebook-1), convert your training NITFs and annotations to a Tensorflow Record file. optionally including image chips that have no annotations (i.e., background only chips) for enhanced False Positive reduction. The steps in this notebook are: </span>\n",
    "> ## 1. Specify the imagery folder (e.g., a folder of NITFs) and the groundtruth training CSV file\n",
    "> ## 2. Make a list if NITFs/images that will be added to the Tensorflow Record for training the model \n",
    "> ## 3. Process the training data and add it to a Tensorflow Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.io.tf_conversion_tools import *\n",
    "import os\n",
    "#os.environ['OPENCV_IO_MAX_IMAGE_PIXELS'] = pow(2,40).__str__() # if you are using PNGs instaed of NITFs and your png files are larger than cv2's default max size\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from osgeo.gdal import Open as gdalOpen\n",
    "from libs.label_name_dict.label_dict import NAME_LABEL_MAP\n",
    "from libs.configs.cfgs import DATASET_NAME, TFRECORD_PATH, TFRECORD_NAME, TRAIN_IMG_CHIP_SIZE, TRAIN_IMG_CHIP_OVRLP\n",
    "print('Dataset name: ', DATASET_NAME)\n",
    "print('Dataset categories including background: ', NAME_LABEL_MAP)\n",
    "print('The Tensorflow Record will be saved as :', os.path.join(TFRECORD_PATH, TFRECORD_NAME))\n",
    "print('The training image chip height & width will be', TRAIN_IMG_CHIP_SIZE, 'pixels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-warning\">\n",
    "    \n",
    "## <span style='color:red'> ^ Check that your ROOT_PATH, DATASET_NAME,  label dictionary, & TFRECORD_PATH are set how you want them ^\n",
    "    \n",
    "## <span style='color:green'> Note for tutorial: We recommend that TRAIN_IMG_CHIP_SIZE (in you config file) be set just large enough for safely maximizing the GPU memory during network training (we found this value to be 2000 pixels for our Tesla V100 GPUs with 32478MiB of memory). But for the tutorial, you can reduce TRAIN_IMG_CHIP_SIZE to 1000 or smaller to speed up the training process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-success\">\n",
    "\n",
    "## <span style='color:Blue'> 1) Specify the NITF directory and training-set groundtruth file and check the format of the groundtruth file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groundtruth csv must be include the following columns:\n",
      "['IMID', 'xLF', 'yLF', 'xRF', 'yRF', 'xRB', 'yRB', 'xLB', 'yLB','class']\n",
      "Your groundtruth contains the following:\n",
      "Index(['IMID', 'xLF', 'yLF', 'xRF', 'yRF', 'xRB', 'yRB', 'xLB', 'yLB',\n",
      "       'class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "raw_images_dir = 'data/IMAGERY/'\n",
    "gt_path = 'data/CSVs/OMITTED_TRAIN_Data_Nightingale_Format.csv'\n",
    "gt_dataframe = pd.read_csv(gt_path)\n",
    "print('groundtruth csv must be include the following columns:')\n",
    "print(\"['IMID', 'xLF', 'yLF', 'xRF', 'yRF', 'xRB', 'yRB', 'xLB', 'yLB','class']\")\n",
    "print('Your groundtruth contains the following:')\n",
    "print(gt_dataframe.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-success\">\n",
    "\n",
    "## <span style='color:Blue'> 2) Get the list of training images from the training-set groundtruth file, shuffle for training, and check that the number of training images and training image id's in groundtruth match. Note that this will only grab images that are included in the training-set csv file, so you don't need to manually separate your images into different folders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found training images: 2\n",
      "found training labels: 2\n"
     ]
    }
   ],
   "source": [
    "labels_id = list(np.unique(gt_dataframe['IMID'].to_numpy(dtype=np.str))) # unique list of image id's\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "all_images = os.listdir(raw_images_dir)\n",
    "random.shuffle(all_images)\n",
    "for i in all_images:\n",
    "    image_id = i.split('.')[0]\n",
    "    if image_id in labels_id:\n",
    "        images.append(i)\n",
    "    \n",
    "\n",
    "print('found training images:', len(images))\n",
    "print('found training labels:', len(labels_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-success\">\n",
    "\n",
    "## <span style='color:Blue'> 3) Convert the training NITFs and training CSV annotations to a Tensorflow Record for training. Be sure to read the docstring for \"format_image_label\" and \"data_2_tfrec\" functions from data.io.tf_conversion_tools. Later, these two functions will allow you to retrain a model on imagery chips where False Positives were found in order to reduce FP occurences with the final model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "### Edit the following parameters #######\n",
    "#########################################\n",
    "image_format = 'nitf' # can be 'nitf' or 'png'\n",
    "#########################################\n",
    "####### Run the cell ####################\n",
    "#########################################\n",
    "\n",
    "img_h = TRAIN_IMG_CHIP_SIZE\n",
    "img_w = TRAIN_IMG_CHIP_SIZE\n",
    "stride_h = TRAIN_IMG_CHIP_SIZE-TRAIN_IMG_CHIP_OVRLP\n",
    "stride_w = TRAIN_IMG_CHIP_SIZE-TRAIN_IMG_CHIP_OVRLP \n",
    "\n",
    "if not os.path.exists(TFRECORD_PATH):\n",
    "    os.makedirs(TFRECORD_PATH)\n",
    "save_path = os.path.join(TFRECORD_PATH, TFRECORD_NAME)\n",
    "print('saving to ', save_path)\n",
    "writer = tf.python_io.TFRecordWriter(path=save_path)\n",
    "\n",
    "total_full_count = 0\n",
    "total_empty_count = 0\n",
    "PIXEL_MEAN = []\n",
    "PIXEL_MEAN_ = []\n",
    "PIXEL_STD = []\n",
    "for idx, img in enumerate(images):\n",
    "    \n",
    "    img_id = img.split('.')[0]\n",
    "    \n",
    "    print(idx, 'reading image', img)\n",
    "    \n",
    "    if image_format == 'png':\n",
    "        img_data = cv2.imread(os.path.join(raw_images_dir, img))\n",
    "        bits = None\n",
    "    elif image_format == 'nitf':\n",
    "        my_nitf = gdalOpen(os.path.join(raw_images_dir, img))\n",
    "        bits = int(my_nitf.GetMetadata()['NITF_ABPP'])\n",
    "        #img_data = my_nitf.GetRasterBand(1).ReadAsArray()\n",
    "        img_data = my_nitf.GetRasterBand(1).GetVirtualMemArray()\n",
    "        \n",
    "    \n",
    "    #box = format_label(gt_dataframe,img_id,list(NAME_LABEL_MAP.keys()))\n",
    "    box = format_image_label(gt_dataframe,img_id,NAME_LABEL_MAP)\n",
    "    \n",
    "    full_count, empty_count, pix_metrics = data_2_tfrec(file_idx = img.split('.')[0], image = img_data, \n",
    "                                         img_format = image_format, bits = bits,\n",
    "                                         boxes_all = box, width = img_w, height = img_h, \n",
    "                                         stride_w = stride_w, stride_h = stride_h, \n",
    "                                         writer = writer, add_random_empties=False)\n",
    "    PIXEL_MEAN.append(pix_metrics['pix_mean'])\n",
    "    PIXEL_MEAN_.append(pix_metrics['pix_mean_normed'])\n",
    "    PIXEL_STD.append(pix_metrics['pix_std_normed'])\n",
    "    total_full_count += full_count\n",
    "    total_empty_count += empty_count\n",
    "    text = 'total chips w/ labels = '+str(total_full_count)+', total hard-negative (empty) chips = ', total_empty_count\n",
    "    print(text)\n",
    "PIXEL_MEAN = np.mean(np.array(PIXEL_MEAN),axis=0)\n",
    "PIXEL_MEAN_= np.mean(np.array(PIXEL_MEAN_),axis=0)\n",
    "PIXEL_STD = np.mean(np.array(PIXEL_STD),axis=0)\n",
    "print('PIXEL_MEAN = ', list(PIXEL_MEAN))\n",
    "print('PIXEL_MEAN_ = ', list(PIXEL_MEAN_))\n",
    "print('PIXEL_STD = ', list(PIXEL_STD))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-success\">\n",
    "\n",
    "## <span style='color:Blue'> You are done converting your data for training the model!\n",
    "    \n",
    "## <span style='color:Blue'> When the above cell finishes running, three variables are printed at the end (PIXEL_MEAN, PIXEL_MEAN_, and PIXEL_STD). These metircs were determiend while processing the imagery data. Update these variables in your cfgs.py file. \n",
    "    \n",
    "## <span style='color:Blue'> If you set \"add_random_empties=True\" in the data_2_tfrec function, or if your groundtruth contained background category labels, then you will also see that the \"total hard-negative (empty) chips\" count is greater than zero. It's probably a bad idea to have more empty chips than chips with labels. Reconfigure some settings and redo the TF Record conversion if that's the case!\n",
    "\n",
    "## <span style='color:Blue'> Doublecheck the settings in your cfgs.py file (in libs/configs/) and then run multi_train_gpu.py (in Training/tools/) from the terminal (see Notebook #3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nightingale_env",
   "language": "python",
   "name": "nightingale_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
