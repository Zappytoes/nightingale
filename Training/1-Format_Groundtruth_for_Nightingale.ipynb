{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-success\">\n",
    "    \n",
    "# <span style='color:Blue'> NOTEBOOK 1: Formatting and Pre-Processing Object-Aligned Annotations for Nightingale \n",
    "\n",
    "## Make sure you are running the *nightingale_env* kernel in this notebook\n",
    "\n",
    "## This notebook is provided as an example workflow to properly format the groundtruth data for training the SCRDet++ model with Nightingale.  A properly formatted groundtruth file for Nightingale will be a csv with the following column headers:\n",
    "\n",
    ">> ## 'IMID','xLF','yLF','xRF','yRF','xRB', 'yRB','xLB', 'yLB','class'\n",
    "\n",
    "## Where \n",
    "> ### 'IMID' is the image name without file extension\n",
    "> ### 'xLF' & 'yLF' are the x,y coordinates of the front-left corner of the object\n",
    "> ### 'xRF' & 'yRF' are the x,y coordinates of the front-right corner of the object\n",
    "> ### 'xRB' & 'yRB' are the x,y coordinates of the back-right corner of the object\n",
    "> ### 'xLB' & 'yLB' are the x,y coordinates of the back-left corner of the object\n",
    "> ### 'class' is the class or cateogry of the object label\n",
    "\n",
    "\n",
    "## We'll use a sample of the OMITTED dataset to work through this notebook. Sample NITFs and groundtruth csv are provided in the data/IMAGERY/ and data/CSVs/ folders. The primary steps in this notebook are:\n",
    "> ## 1. Grouping the OMITTED sub-categories into higher-level classes and removing unwanted classes from the groundtruth\n",
    "> ## 2. Converting OMITTED's *Front,Back,Left,Right* data object point annotations to a 4-corner-point format using the fblr2corners function\n",
    "> ## 3. Formatting the groundtruth files for Nightingale\n",
    "> ## 4. Partitioning the groundtruth data into Training and Test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-success\">\n",
    "\n",
    "## <span style='color:Blue'> Imports </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X11hFVN45ptc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import glob\n",
    "from libs.box_utils.coordinate_convert import fblr2corners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-success\">\n",
    "\n",
    "## <span style='color:Blue'> First, we'll define the data and convert the OMITTED object labels to 3 classes, class1, class2, and class3 </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-warning\">\n",
    "\n",
    "## <span style='color:black'> (Optional) Before you start, add your imagery to the Nightingale/Training/data/IMAGERY folder and your groundtruth csv to the Nightingale/Training/data/CSVs folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) set the path to the image directory and groundtruth file\n",
    "img_path = 'data/IMAGERY/'\n",
    "gt_path = 'data/CSVs/sample_OMITTED.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 2) Read in the groundtruth csv as a pandas dataframe\n",
    "\n",
    "df = pd.read_csv(gt_path)\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-success\">\n",
    "\n",
    "## Notice that the raw OMITTED data has the 'objType' column and 'objStatus' column. This is because OMITTED was interested in not only the type of object, but what the object was doing. For simplicity, we'll use the 'objType' and 'objStatus' to filter out unwanted categories and rename kept categories to either 'class1', 'class2', or 'class3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# 3) Make a list of the NITF files in the image directory and print the number of total NITFs\n",
    "image_files = os.listdir(img_path)\n",
    "print(len(image_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  unique image ids in the groundtruth file\n"
     ]
    }
   ],
   "source": [
    "# 4) Make a numpy array of the image id's column in the groundtruth file \n",
    "# and add a column called IMID to match Nightingale header format for image id's. \n",
    "# Print the number of unique image id's.\n",
    "IMID = df['ImageID'].to_numpy(np.str)\n",
    "df['IMID'] = IMID\n",
    "print(len(np.unique(IMID)), ' unique image ids in the groundtruth file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5) To a new list, convert the class1 and class2 sub-categories so that only 3 classes remain, leaving other classes labled as \"Junk\"\n",
    "\n",
    "count = 0\n",
    "class3 = []\n",
    "for obj_class_obj_status in df[['objType','objStatus']].to_numpy(dtype=np.str):\n",
    "    obj_class_obj_status = obj_class_obj_status[0]+obj_class_obj_status[1]\n",
    "    \n",
    "    if 'class1' in obj_class_obj_status:\n",
    "        class3.append('class1')\n",
    "        \n",
    "    elif 'class2_super_cat' in obj_class_obj_status:\n",
    "        \n",
    "        if 'class2_subcat' in obj_class_obj_status:\n",
    "            class3.append('class2')\n",
    "        else:\n",
    "            class3.append('class3')\n",
    "    else:\n",
    "        class3.append('Junk')\n",
    "    \n",
    "    count+=1\n",
    "print(count, 'total objects converted')\n",
    "print('The new classes are ',np.unique(np.asarray(class3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) add the new class lables list to the dataframe under the 'class' header\n",
    "df['class'] = class3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) create a new dataframe that only contains the 3 classes we are interested in\n",
    "df_3class = df[df['class'].isin(['class1','class2','class3'])]\n",
    "df_3class = df_3class.reset_index().drop('index',axis=1)\n",
    "df_3class.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-success\">\n",
    "    \n",
    "## <span style='color:Blue'> Next we'll convert the *front, back, left, right* object pixel point format to 4-corner-point format and then create a new dataframe that contains only the columns required for Nightingale </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Run fblr2corners on each annotation in the groundtruth dataframe and then create a new column for each corner point\n",
    "corners = []\n",
    "for index,row in df_3class.iterrows():\n",
    "    fblr = row[['firstX','firstY','secondX','secondY','thirdX', 'thirdY','fourthX', 'fourthY']].to_numpy(np.int64)\n",
    "    #print(fblr)\n",
    "    BBOX = fblr2corners(fblr)\n",
    "    corners.append(BBOX)\n",
    "corners = np.asarray(corners)\n",
    "df_3class['xLF'] = corners[:,0]\n",
    "df_3class['yLF'] = corners[:,1]\n",
    "df_3class['xRF'] = corners[:,2]\n",
    "df_3class['yRF'] = corners[:,3]\n",
    "df_3class['xRB'] = corners[:,4]\n",
    "df_3class['yRB'] = corners[:,5]\n",
    "df_3class['xLB'] = corners[:,6]\n",
    "df_3class['yLB'] = corners[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) check new dataframe, now with xLF,yLF,xRF,yRF,xRB,yRB,xLB,yLB corner points for each annotation\n",
    "df_3class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['IMID', 'xLF', 'yLF', 'xRF', 'yRF', 'xRB', 'yRB', 'xLB', 'yLB',\n",
      "       'class'],\n",
      "      dtype='object')\n",
      "36 total annoations\n"
     ]
    }
   ],
   "source": [
    "# 3) To a new dataframe, send only the required annotation \n",
    "# information for Nightingale, which includes the image id, \n",
    "# four corner points, and category name\n",
    "df_3class_nightingale = df_3class[['IMID','xLF','yLF','xRF','yRF','xRB', 'yRB','xLB', 'yLB','class']]\n",
    "print(df_3class_nightingale.columns)\n",
    "print(len(df_3class_nightingale), 'total annoations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-success\">\n",
    "\n",
    "## <span style='color:Blue'> Finally, we'll partition the data by randomly shuffling the image id's and writing separate training and test CSVs to disk </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  2 training images\n",
      "There are  1 test images\n"
     ]
    }
   ],
   "source": [
    "# 1) randomly shuffle a list of unique image id's and break them up into a random 70/30 split using a fixed random seed\n",
    "IMIDs = list(np.unique(df_3class_nightingale['IMID'].to_numpy()))\n",
    "random.Random(4).shuffle(IMIDs)\n",
    "train_im_list = IMIDs[0:int(len(IMIDs)*0.7)]\n",
    "test_im_list = IMIDs[int(len(IMIDs)*0.7):int(len(IMIDs))]\n",
    "print('There are ', len(train_im_list), 'training images')\n",
    "print('There are ', len(test_im_list), 'test images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Create the training-data dataframe\n",
    "df_3class_nightingale_train = df_3class_nightingale[df_3class_nightingale.IMID.isin(train_im_list)]\n",
    "df_3class_nightingale_train = df_3class_nightingale_train.reset_index().drop('index',axis=1)\n",
    "df_3class_nightingale_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) create the test-data dataframe\n",
    "df_3class_nightingale_test = df_3class_nightingale[df_3class_nightingale.IMID.isin(test_im_list)]\n",
    "df_3class_nightingale_test = df_3class_nightingale_test.reset_index().drop('index',axis=1)\n",
    "df_3class_nightingale_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-warning\">\n",
    "\n",
    "## <span style='color:red'> Before we write our training and testing annotations to their own separate csv files, let's check the numbers to make sure everything looks right </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There were originally 36 total annotations in our simplified 3-category dataset. \n",
    "# Do our training and test annotation counts add up?\n",
    "len(df_3class_nightingale_train), len(df_3class_nightingale_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the numbers of examples of each class in our training and test set\n",
    "train_class_count = np.unique(df_3class_nightingale_train['class'].to_numpy(), return_counts=True)\n",
    "test_class_count = np.unique(df_3class_nightingale_test['class'].to_numpy(), return_counts=True)\n",
    "print(train_class_count)\n",
    "print(test_class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# And let's double check the number of images in the training and test set\n",
    "train_im_count = np.unique(df_3class_nightingale_train['IMID'].to_numpy())\n",
    "test_im_count = np.unique(df_3class_nightingale_test['IMID'].to_numpy())\n",
    "print(len(train_im_count))\n",
    "print(len(test_im_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-success\">\n",
    "\n",
    "## <span style='color:Blue'> Everything looks good! Let's write our training and test dataframes to new csv files </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3class_nightingale_train.to_csv('data/CSVs/OMITTED_TRAIN_Data_Nightingale_Format.csv',index=False)\n",
    "df_3class_nightingale_test.to_csv('data/CSVs/OMITTED_TEST_Data_Nightingale_Format.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-success\">\n",
    "\n",
    "# <span style='color:Green'> Great! Now we can move on to the next notebook for adding our training data to a Tensorflow Record. Open Notebook-2, \"2-Make_TF_Record.ipynb\" to get started. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ViewImages_BBoxes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nightingale_env",
   "language": "python",
   "name": "nightingale_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
